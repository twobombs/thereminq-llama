#!/bin/bash

# X-run script
rm /tmp/.X0-lock
Xvfb :0 -screen 0 1920x1080x24+32 -ac &
export DISPLAY=:0&&startxfce4 &
sleep 10
x0vncserver -display :0 -passwordfile ~/.vnc/passwd &
/usr/share/novnc/utils/launch.sh --vnc localhost:5900 &
service xrdp start && xrdp &

export DISPLAY=:0&&xterm -e "xset s off" &
export DISPLAY=:0&&xterm -e "neofetch && tail -f /dev/null" &
export DISPLAY=:0&&exo-open --launch TerminalEmulator &

#fetch model
rm Meta-Llama-3.1-8B-q4_k_s.gguf && wget https://huggingface.co/Twobombs/llama31-8B/resolve/main/Meta-Llama-3.1-8B-q4_k_s.gguf &

# show system config in logs
nvidia-smi
ifconfig

# start OpenAI API simulator
# python3 -m llama_cpp.server --model /Llama-3-DARE-8B.IQ3_M.gguf &

sleep 10

# precompile qrack kernels
./qrack/_build/qrack_cl_precompile

# start ollama service
./usr/bin/ollama serve &

# start codecarbon service 
cd /root
echo '[codecarbon] log_level = DEBUG save_to_api = True experiment_id =' > .codecarbon.config
codecarbon init >> .codecarbon.config
codecarbon monitor

tail -f /dev/null
