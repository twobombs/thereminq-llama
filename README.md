# ThereminQ-LLaMa : baking a quantum layer caek

This repo is alpha and dedicated to training ggml LLaMa's with QC data

![2a40063099465fee941a701289810666](https://github.com/twobombs/thereminq-llama/assets/12692227/6097d5e2-92fa-4bff-9297-c26d98f31d84)

--------

Qrackmin:POCL + LLaMa.cpp integrated container image

docker run --privileged --gpus all [-v /path-to-/models/:/text-generation-webui/models] [-p 7860:7860] [-p 5173:5173] -d twobombs/thereminq-llama[:tag] 
- latest includes dependancies and a LLama2 2bit model 
- opencl for python llama.cpp opencl support
- cuda for python llama.cpp cuda support
- cli for LLama.cpp compiled versions
- spark adds spark services to opencl image
- chatui for web based LLM interface & huggingface URL tunnel

Work in progress 

![QCAI-chat drawio](https://github.com/twobombs/thereminq-llama/assets/12692227/1421f71c-b1cc-4562-a59c-c0d9448be562)


--------

Look ma, no K8s

- orchestrate for orchestration of several container images through docker socket link

--------

Optional
- Download a ton of hugging face bin files through fetch-bins.sh

  https://github.com/twobombs/thereminq-llama/blob/main/misc/fetch-bins.sh

--------

Credits for Qrack and LLaMa.cpp go to

Dan Strano https://github.com/unitaryfund/qrack

Georgi Gerganov https://github.com/ggerganov/llama.cpp

... and their respective contributers

--------
![Untitled](https://user-images.githubusercontent.com/12692227/232248160-f4c2a3aa-fd19-4b62-b6f2-532ec44ca0e3.png)

poem generated by ChatGPT 3
