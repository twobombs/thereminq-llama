# ThereminQ-llama : baking a Quantum layer caek

This repo is alpha and dedicated to extending `GGUF` llama LLMs with QC data on Agent steriods

![2a40063099465fee941a701289810666](https://github.com/twobombs/thereminq-llama/assets/12692227/6097d5e2-92fa-4bff-9297-c26d98f31d84)

--------

`Qrackmin` + `llama.cpp` + `open-interpreter` integrated container image stack

```bash
docker run --gpus all [-v /path-to-/models:/text-generation-webui/models] [-p 7860:7860] [-p 5173:5173] [-p 5601:5601] [-p 9200:9200] -d twobombs/thereminq-llama[:tag] 
````

- `latest` includes QC/AI dependancies and a LLama3 model
- `cli` LLama.cpp compiled versions for direct CLI interaction such as model [conversion](https://github.com/ggerganov/llama.cpp?tab=readme-ov-file#prepare-and-quantize)
- `chatui` for web based LLM interfaces & huggingface URL tunnel
- `agent` for OpenInterpreterUI/CLI with Ollama3 integration
  
--------

Work in progress 

![QCAI-chat drawio](https://github.com/twobombs/thereminq-llama/assets/12692227/53d15ddb-1599-4787-bc0e-962672d81cf1)


--------

Optional
- Download a ton of hugging face bin files through [fetch-bins.sh](https://github.com/twobombs/thereminq-llama/blob/main/misc/fetch-bins.sh)

--------

Credits for Qrack, LLaMa.cpp and Open Interpreter go to

Dan Strano https://github.com/unitaryfund/qrack

Georgi Gerganov https://github.com/ggerganov/llama.cpp

Open Interpreter project https://www.openinterpreter.com/

... and their respective contributers

--------

![Untitled](https://user-images.githubusercontent.com/12692227/232248160-f4c2a3aa-fd19-4b62-b6f2-532ec44ca0e3.png)

poem generated by [ChatGPT 3](https://chat.openai.com/)
