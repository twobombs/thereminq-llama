# ThereminQ-LLaMa : baking a quantum layer caek

This repo is alpha and dedicated to extending `GGUF` LLaMa LLMs with QC data on Agent steriods

![2a40063099465fee941a701289810666](https://github.com/twobombs/thereminq-llama/assets/12692227/6097d5e2-92fa-4bff-9297-c26d98f31d84)

--------

`Qrackmin:POCL` + `LLaMa.cpp` integrated container image

```bash
docker run --gpus all [-v /path-to-/models:/text-generation-webui/models] [-p 7860:7860] [-p 5173:5173] [-p 5601:5601] [-p 9200:9200] -d twobombs/thereminq-llama[:tag] 
````

- `latest` includes dependancies and a LLama2 4bit model including mlflow, autogenstudio and crewai
- `cli` for LLama.cpp compiled versions
- `chatui` for web based LLM interfaces & huggingface URL tunnel
- `agent` for OpenInterpreterUI/CLI with Ollama3 integration
  
--------

Work in progress 

![QCAI-chat drawio](https://github.com/twobombs/thereminq-llama/assets/12692227/53d15ddb-1599-4787-bc0e-962672d81cf1)


--------

Optional
- Download a ton of hugging face bin files through [fetch-bins.sh](https://github.com/twobombs/thereminq-llama/blob/main/misc/fetch-bins.sh)

--------

Credits for Qrack and LLaMa.cpp go to

Dan Strano https://github.com/unitaryfund/qrack

Georgi Gerganov https://github.com/ggerganov/llama.cpp

... and their respective contributers

--------

![Untitled](https://user-images.githubusercontent.com/12692227/232248160-f4c2a3aa-fd19-4b62-b6f2-532ec44ca0e3.png)

poem generated by [ChatGPT 3](https://chat.openai.com/)
