FROM pytorch/pytorch:latest

RUN export DEBIAN_FRONTEND=noninteractive && apt update && apt install -y git python3-pip mc wget

# install nod-ia llama
RUN git clone https://github.com/nod-ai/llama.git
RUN cd llama && pip install -r requirements.txt 
RUN cd llama && pip install -e . 

# install lit-llama
RUN git clone https://github.com/Lightning-AI/lit-llama
RUN cd lit-llama && pip install -r requirements.txt 

#install llama.cpp
RUN git clone https://github.com/ggerganov/llama.cpp 
RUN cd llama.cpp/models && wget https://huggingface.co/Pi3141/alpaca-native-13B-ggml/resolve/main/ggml-model-q8_0.bin
RUN cd llama.cpp && make -j 

COPY run /root/run
RUN chmod 744 /root/run*

ENV NVIDIA_VISIBLE_DEVICES all
ENV NVIDIA_DRIVER_CAPABILITIES graphics,utility,compute
ENTRYPOINT /root/run
