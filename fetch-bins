#!/bin/bash
# fetch bins from huggingface
# 230 GB - might take a while
# source https://huggingface.co/decapoda-research

# llama-65b-hf
mkdir llama-65b-hf && cd llama-65b-hf
for i in {1..9}; do
  wget https://huggingface.co/decapoda-research/llama-65b-hf/resolve/main/pytorch_model-0000"$i"-of-00081.bin
done
for i in {10..81}; do
  wget https://huggingface.co/decapoda-research/llama-65b-hf/resolve/main/pytorch_model-000"$i"-of-00081.bin
done

# llama-7b-hf
cd .. && mkdir llama-7b-hf && cd llama-7b-hf
for i in {1..9}; do
  wget https://huggingface.co/decapoda-research/llama-7b-hf/resolve/main/pytorch_model-0000"$i"-of-00033.bin
done
for i in {10..33}; do
  wget https://huggingface.co/decapoda-research/llama-7b-hf/resolve/main/pytorch_model-000"$i"-of-00033.bin
done
