FROM twobombs/thereminq-llama

RUN CMAKE_ARGS="-DLLAMA_CLBLAS=on" FORCE_CMAKE=1 pip install llama-cpp-python

ENV NVIDIA_VISIBLE_DEVICES all
ENV NVIDIA_DRIVER_CAPABILITIES graphics,utility,compute
ENTRYPOINT /root/run
